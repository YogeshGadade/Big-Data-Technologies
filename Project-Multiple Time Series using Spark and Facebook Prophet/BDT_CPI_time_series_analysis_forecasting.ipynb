{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BDT CPI time series analysis forecasting.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xBHg9y9Utia"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from fbprophet import Prophet\n",
        "\n",
        "# Initialising parameters\n",
        "plt.rcParams['figure.figsize'] = (15, 8)\n",
        "plt.rcParams['axes.grid'] = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark # Install pyspark"
      ],
      "metadata": {
        "id": "DAOCZGH7Uwbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession \n",
        "import pyspark\n",
        "\n",
        "spark = SparkSession.builder.master('local').getOrCreate()\n",
        "# Load csv file in pandas\n",
        "df = pd.read_csv(\"/content/sample_data/26 counties monthly CPI.csv\")"
      ],
      "metadata": {
        "id": "yXbj-a4IUyGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of the dataset: \", df.shape)\n",
        "print(\"\\nSize of the pandas table:\", df.info())"
      ],
      "metadata": {
        "id": "PLInR8LrU76f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OBSERVATION: Number of rows we have: 30,482 with 8 features     1.9+ MB"
      ],
      "metadata": {
        "id": "Z6ZZcSM6U8AV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "upK-irFJU8F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df['LOCATION'].unique()), df['LOCATION'].unique()"
      ],
      "metadata": {
        "id": "tBM3Hf5lVUtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keeping only 4 countries \n",
        "df=df[df['LOCATION'].apply(lambda x: x=='IND'or x=='USA' or x=='RUS' or x=='FIN')]"
      ],
      "metadata": {
        "id": "Em0t8pFgab1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df['LOCATION'].unique()), df['LOCATION'].unique()"
      ],
      "metadata": {
        "id": "i3WOwUyxb08X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of the dataset: \", df.shape)\n",
        "print(\"\\nSize of the pandas table:\", df.info())"
      ],
      "metadata": {
        "id": "0F48p7Weg8xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={'TIME': 'Date', 'LOCATION': 'Location'}, inplace=True)"
      ],
      "metadata": {
        "id": "YRImeImXVwWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df[['Date', 'Value', 'Location']]"
      ],
      "metadata": {
        "id": "tsh1G0o6VvBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "Na6_Sd6tWSeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "WVY_D9UgWOsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True)\n",
        "df['Value']=df['Value'].astype(float)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "C9ixy5ZsWViY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Date'].min(), df['Date'].max()"
      ],
      "metadata": {
        "id": "8EiweS6RWVoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_df = df.set_index('Date')\n",
        "item_df=item_df[['Value', 'Location']]\n",
        "item_df.head()"
      ],
      "metadata": {
        "id": "e_DiFNXVWVrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_df[item_df['Location'] == 'FIN']['Value'].plot()"
      ],
      "metadata": {
        "id": "7B4y1gSpWlQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iA8WfcYKxZpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stationarity Check"
      ],
      "metadata": {
        "id": "GTTiLYz8xzv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for Location in list(df['Location'].unique()):\n",
        "  item_df[item_df['Location'] == Location]['Value'].plot(title=Location)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "f-Ts0WFcAAFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#zip basically combines result,labels\n",
        "# Augmented Dickey–Fuller test (ADF) tests\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "def adfuller_test(sales):\n",
        "    result=adfuller(sales)\n",
        "    labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations Used']\n",
        "    for value,label in zip(result,labels):\n",
        "        print(label+' : '+str(value) )\n",
        "    if result[1] <= 0.05:\n",
        "        print(\"strong evidence against the null hypothesis(Ho), reject the null hypothesis. Data has no unit root and is stationary\")\n",
        "    else:\n",
        "        print(\"weak evidence against null hypothesis, time series has a unit root, indicating it is non-stationary \")\n",
        "        \n",
        "# source: https://www.kaggle.com/code/avi111297/predicting-sales-using-arima-sarimax-tsf-model"
      ],
      "metadata": {
        "id": "eQorpeQxxZxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmented Dickey–Fuller test (ADF) tests\n",
        "for Location in list(df['Location'].unique()):\n",
        "  print(\"\\nLocation is: \", Location)\n",
        "  adfuller_test(item_df[item_df['Location'] == Location]['Value'])"
      ],
      "metadata": {
        "id": "OP4p14KyxcDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install statsmodels"
      ],
      "metadata": {
        "id": "EFvRgtaQ-NYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.set_index(\"Date\")[['Value']].head()"
      ],
      "metadata": {
        "id": "7zJCs1NW_FNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictCrypto={'AUT': 1, 'BEL': 2, 'CAN': 3, 'CZE': 4, 'DNK': 5, 'FIN': 6, 'FRA': 7, 'DEU': 8, 'GRC': 9,\n",
        "        'HUN': 10, 'ISL': 11, 'IRL': 12, 'ITA': 13, 'JPN': 14, 'KOR': 15, 'LUX': 16, 'MEX': 17, 'NLD': 18,\n",
        "        'NOR': 19, 'POL': 20, 'PRT': 21, 'SVK': 22, 'ESP': 23, 'SWE': 24, 'CHE': 25, 'TUR': 26, 'GBR': 27,\n",
        "        'USA': 28, 'BRA': 29, 'CHL': 30, 'CHN': 31, 'EST': 32, 'IND': 33, 'IDN': 34, 'ISR': 35, 'RUS': 36,\n",
        "        'SVN': 37, 'ZAF': 38, 'OECD': 39, 'OECDE': 40, 'G-7': 41, 'COL': 42, 'LVA': 43, 'SAU': 44, 'EA19': 45,\n",
        "        'ARG': 46, 'LTU': 47, 'G-20': 48, 'EU27_2020': 49}\n",
        "dictCrypto = {'FIN': 1, 'USA': 2, 'IND': 3, 'RUS': 4} \n",
        "df['LocId']=df['Location'].apply(lambda x: dictCrypto[x])"
      ],
      "metadata": {
        "id": "BtIk3PtTWlXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "P9xRJFkQWlbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time \n",
        "from sklearn.metrics import mean_absolute_error\n",
        "def forecast_sales(crypto_pd):\n",
        "  model = Prophet(interval_width=0.95, seasonality_mode= 'multiplicative', daily_seasonality=True, weekly_seasonality=True, yearly_seasonality=True)\n",
        "  model.fit(crypto_pd)\n",
        "  future_pd = model.make_future_dataframe(periods=30, freq='M')\n",
        "  forecast_pd = model.predict(future_pd)\n",
        "  f_pd = forecast_pd[['ds', 'yhat', 'yhat_upper', 'yhat_lower']].set_index('ds')\n",
        "  st_pd = crypto_pd[['ds', 'Location', 'y']].set_index('ds')\n",
        "  result_pd = f_pd.join(st_pd, how='left')\n",
        "  result_pd.reset_index(level=0, inplace=True)\n",
        "  result_pd['Location'] = crypto_pd['Location'].iloc[0]\n",
        "\n",
        "  #from fbprophet.diagnostics import cross_validation\n",
        "  #cv_results = cross_validation( model = model, initial = pd.to_timedelta(5,unit=\"d\"), horizon = pd.to_timedelta(5,unit=\"d\"))\n",
        "  #print(\"cv_results:\", cv_results)\n",
        "  \n",
        "  return result_pd[['ds', 'Location', 'y', 'yhat', 'yhat_upper', 'yhat_lower']]\n",
        "\n",
        "\n",
        "tick= time.time()\n",
        "for cryptoName in list(df['Location'].unique()):\n",
        "  pdIndividualCrypto=df[df['Location'] == Location][['Date','Location', 'Value']].rename(columns={'Date': 'ds', 'Value': 'y'})\n",
        "  final_df=forecast_sales(pdIndividualCrypto)\n",
        "  \n",
        "\n",
        "  # calculate Mean Absolute Error (MAE) between expected and predicted values for december\n",
        "  y_true = final_df.dropna()['y'].values\n",
        "  y_pred = final_df.dropna()['yhat'].values\n",
        "\n",
        "  mae = mean_absolute_error(y_true, y_pred)\n",
        "  print(Location, ': MAE: %.3f' % mae)\n",
        "\n",
        "  final_df[['y', 'yhat']].plot(title=Location + ': MAE: %.3f' % mae)\n",
        "  \n",
        "tock=time.time()\n",
        "TotalTime=tock-tick\n",
        "print(\"Total time taken: {} sec.s\".format(round(tock-tick, 3)))"
      ],
      "metadata": {
        "id": "1rht3h8wXfVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spark "
      ],
      "metadata": {
        "id": "OWmk2TmJ2v0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sdf = spark.createDataFrame(df)\n",
        "sdf.printSchema() #data type of each col\n",
        "sdf.show(5) #It gives you head of pandas DataFrame\n",
        "sdf.count() #500 records"
      ],
      "metadata": {
        "id": "iF9IrcgWXmLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf.select(['LocId']).groupby('LocId').agg({'LocId': 'count'}).show()"
      ],
      "metadata": {
        "id": "IJWcnSs-XmOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf.createOrReplaceTempView(\"Crypto\")\n",
        "spark.sql(\"select LocId, count(*) from Crypto group by LocId order by LocId\").show()"
      ],
      "metadata": {
        "id": "edtOfvJVXpWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql = \"SELECT LocId, Date as ds, sum(Value) as y FROM Crypto GROUP BY LocId, ds ORDER BY LocId, ds\"\n",
        "spark.sql(sql).show()"
      ],
      "metadata": {
        "id": "2E47nZ1KXpZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_part = (spark.sql(sql).repartition(spark.sparkContext.defaultParallelism, ['LocId'])).cache()\n",
        "sdf.explain()"
      ],
      "metadata": {
        "id": "1qRIa76FXpcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "result_schema = StructType([\n",
        "                  StructField('ds', TimestampType()),\n",
        "                  StructField('LocId', IntegerType()),\n",
        "                  StructField('y', DoubleType()),\n",
        "                  StructField('yhat', DoubleType()),\n",
        "                  StructField('yhat_upper', DoubleType()),\n",
        "                  StructField('yhat_lower', DoubleType())\n",
        "])"
      ],
      "metadata": {
        "id": "4LB5xn3FXwrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
        "@pandas_udf(result_schema, PandasUDFType.GROUPED_MAP)\n",
        "def forecast_sales(crypto_pd):\n",
        "  #model = Prophet(interval_width=0.95, seasonality_mode= 'multiplicative', weekly_seasonality=True, yearly_seasonality=True)\n",
        "  model = Prophet(interval_width=0.95, seasonality_mode= 'multiplicative', daily_seasonality=True, weekly_seasonality=True, yearly_seasonality=True)\n",
        "  model.fit(crypto_pd)\n",
        "  future_pd = model.make_future_dataframe(periods=30, freq='M')\n",
        "  forecast_pd = model.predict(future_pd)\n",
        "  f_pd = forecast_pd[['ds', 'yhat', 'yhat_upper', 'yhat_lower']].set_index('ds')\n",
        "  st_pd = crypto_pd[['ds', 'LocId', 'y']].set_index('ds')\n",
        "  result_pd = f_pd.join(st_pd, how='left')\n",
        "  result_pd.reset_index(level=0, inplace=True)\n",
        "  result_pd['LocId'] = crypto_pd['LocId'].iloc[0]\n",
        "\n",
        "  return result_pd[['ds', 'LocId', 'y', 'yhat', 'yhat_upper', 'yhat_lower']]"
      ],
      "metadata": {
        "id": "MW_cKRkMXwuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import current_date\n",
        "tick=time.time()\n",
        "results = (store_part.groupby('LocId').apply(forecast_sales).withColumn('training_date', current_date()))\n",
        "results.cache()\n",
        "results.show(5)\n",
        "tock=time.time()\n",
        "print(\"Total time taken: {} seconds\".format((tock-tick)/60))"
      ],
      "metadata": {
        "id": "B56bdnXPXzWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.coalesce(1)\n",
        "print(results.count())\n",
        "results.createOrReplaceTempView('forecasted')\n",
        "spark.sql(\"SELECT LocId, count(*) FROM  forecasted GROUP BY LocId\").show()"
      ],
      "metadata": {
        "id": "lFAh0XsKXzZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = results.toPandas()\n",
        "final_df.head()"
      ],
      "metadata": {
        "id": "XrpbvDRAXzd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictCrypto={1: 'bitcoin', 2: 'ethereum', 3: 'cardano', 4: 'tether'}\n",
        "dictCrypto={1: 'AUT', 2:'BEL', 3:'CAN', 4:'CZE', 5:'DNK', 6:'FIN', 7:'FRA', 8:'DEU',\n",
        "            9: 'GRC', 10: 'HUN', 11: 'ISL', 12: 'IRL', 13: 'ITA', 14: 'JPN', 15: 'KOR',\n",
        "            16: 'LUX', 17: 'MEX', 18: 'NLD', 19: 'NOR', 20: 'POL', 21: 'PRT', 22:'SVK', \n",
        "            23:'ESP', 24:'SWE', 25:'CHE', 26:'TUR', 27:'GBR', 28: 'USA', 29: 'BRA', 30: 'CHL', 31: 'CHN', \n",
        "            32: 'EST', 33: 'IND', 34: 'IDN', 35: 'ISR', 36: 'RUS', 37: 'SVN', 38: 'ZAF', \n",
        "            39: 'OECD', 40: 'OECDE', 41: 'G-7', 42:'COL', 43:'LVA', 44:'SAU', 45:'EA19',\n",
        "            46: 'ARG', 47:'LTU', 48:'G-20', 49:'EU27_2020'}\n",
        "dictCrypto = {1: 'FIN', 2: 'USA', 3: 'IND', 4: 'RUS'} \n",
        "\n",
        "final_df['Location']=final_df['LocId'].apply(lambda x: dictCrypto[x])\n",
        "final_df.head()"
      ],
      "metadata": {
        "id": "BQuBRKsnXwwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df[final_df['Location'] == 'FIN'][['y', 'yhat']].plot()"
      ],
      "metadata": {
        "id": "mfC3PYkmX6ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = final_df.set_index('ds')\n",
        "for Location in list(final_df.Location.unique()):\n",
        "  #final_df.query('CryptoName == {}'.format(CryptoName))[['y', 'yhat']].plot()\n",
        "  \n",
        "  pdTemp=final_df[final_df['Location'] == Location][['y', 'yhat']]\n",
        "  \n",
        "  # calculate Mean Absolute Error (MAE) between expected and predicted values for december\n",
        "  y_true = pdTemp.dropna()['y'].values\n",
        "  y_pred = pdTemp.dropna()['yhat'].values\n",
        "\n",
        "  mae = mean_absolute_error(y_true, y_pred)\n",
        "  print(Location, ': MAE: %.3f' % mae)\n",
        "\n",
        "  pdTemp[['y', 'yhat']].plot(title=Location + ': MAE: %.3f' % mae)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "w4sHc6xXX6xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XWSHqEtOX6yb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}