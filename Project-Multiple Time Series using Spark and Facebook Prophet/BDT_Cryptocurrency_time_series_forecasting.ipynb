{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BDT Cryptocurrency time series forecasting.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Goal: Multiple Time Series modeling using Apache Spark and Facebook Prophet\n",
        "\n",
        "#### Data set: \n",
        "1. Crypto-currencies data set (last 5 years data for different crypto currencies)\n",
        "2. Additional: In addition to this if possible will try to implement the same for Inflation (CPI) data set of different countries (300,000+ rows for 200+ countries)\n",
        "\n",
        "#### Processes: Data processing, EDA, multiple time series modeling\n",
        "#### Technologies: Spark, Python(pySpark), Databricks"
      ],
      "metadata": {
        "id": "BfZhUCCzlMKV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmgxvydjQepv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from fbprophet import Prophet\n",
        "\n",
        "# Initialising parameters\n",
        "plt.rcParams['figure.figsize'] = (15, 8)\n",
        "plt.rcParams['axes.grid'] = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark # Install pyspark"
      ],
      "metadata": {
        "id": "raPfxCZcRpRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession \n",
        "import pyspark\n",
        "\n",
        "spark = SparkSession.builder.master('local').getOrCreate()\n",
        "# Load csv file in pandas\n",
        "df = pd.read_csv(\"/content/sample_data/4BitcoinsLast10YearsData.csv\")"
      ],
      "metadata": {
        "id": "ikqWiurhRsEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of the dataset: \", df.shape)\n",
        "print(\"\\nSize of the pandas table:\", df.info())"
      ],
      "metadata": {
        "id": "_7m_EOqBpcMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OBSERVATION: Number of rows we have: 10,015 with 4 features"
      ],
      "metadata": {
        "id": "xtHz4-aqrvjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "O4zfsZDRRw6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df[['Date', 'Close', 'CryptoName']]"
      ],
      "metadata": {
        "id": "wKUZaVCwbo0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "-vbMsb4FWcjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "zWmDXT1dilZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True)\n",
        "df['Close']=df['Close'].astype(float)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "CRNc8PpbdFfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Date'].min(), df['Date'].max()"
      ],
      "metadata": {
        "id": "jyqcE9io6g2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.CryptoName.unique()"
      ],
      "metadata": {
        "id": "wxhw35k4Re3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.set_index(\"Date\")[[\"Close\"]].plot(figsize=(18, 8))"
      ],
      "metadata": {
        "id": "2QX-K4WCSE1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True)"
      ],
      "metadata": {
        "id": "Dt8BA52BSFGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_df = df.set_index('Date')\n",
        "item_df=item_df[['Close', 'CryptoName']]\n",
        "item_df.head()"
      ],
      "metadata": {
        "id": "awFTqudpSkGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_df[item_df['CryptoName'] == 'bitcoin']['Close'].plot()"
      ],
      "metadata": {
        "id": "gCo0rJPsRHfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictCrypto={'bitcoin': 1, 'ethereum': 2, 'cardano': 3, 'tether': 4}\n",
        "df['CryptoId']=df['CryptoName'].apply(lambda x: dictCrypto[x])"
      ],
      "metadata": {
        "id": "pXKrhp21eSAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# "
      ],
      "metadata": {
        "id": "7dkabMHSX7XF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "MBktXCacjDH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_df = df.set_index('Date')\n",
        "item_df.query('CryptoId == 1')[['Close']].plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KotTXTTai6YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for CryptoName in list(df['CryptoName'].unique()):\n",
        "  item_df[item_df['CryptoName'] == CryptoName]['Close'].plot(title=CryptoName)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "FEOsbDUoAhJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stationarity Check\n",
        "#zip basically combines result,labels\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "def adfuller_test(sales):\n",
        "    result=adfuller(sales)\n",
        "    labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations Used']\n",
        "    for value,label in zip(result,labels):\n",
        "        print(label+' : '+str(value) )\n",
        "    if result[1] <= 0.05:\n",
        "        print(\"strong evidence against the null hypothesis(Ho), reject the null hypothesis. Data has no unit root and is stationary\")\n",
        "    else:\n",
        "        print(\"weak evidence against null hypothesis, time series has a unit root, indicating it is non-stationary \")\n",
        "        \n",
        "# source: https://www.kaggle.com/code/avi111297/predicting-sales-using-arima-sarimax-tsf-model\n",
        "\n",
        "for CryptoName in list(df['CryptoName'].unique()):\n",
        "  print(\"\\nCrypto Currency: \", CryptoName)\n",
        "  adfuller_test(item_df[item_df['CryptoName'] == CryptoName]['Close'])"
      ],
      "metadata": {
        "id": "6ErYPapSzMpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "j7hvwmyC_nxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# "
      ],
      "metadata": {
        "id": "W-L4pYUWk7_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time \n",
        "from sklearn.metrics import mean_absolute_error\n",
        "def forecast_sales(crypto_pd):\n",
        "  model = Prophet(interval_width=0.95, seasonality_mode= 'multiplicative', daily_seasonality=True, weekly_seasonality=True, yearly_seasonality=True)\n",
        "  model.fit(crypto_pd)\n",
        "  future_pd = model.make_future_dataframe(periods=5, freq='d')\n",
        "  forecast_pd = model.predict(future_pd)\n",
        "  f_pd = forecast_pd[['ds', 'yhat', 'yhat_upper', 'yhat_lower']].set_index('ds')\n",
        "  st_pd = crypto_pd[['ds', 'CryptoName', 'y']].set_index('ds')\n",
        "  result_pd = f_pd.join(st_pd, how='left')\n",
        "  result_pd.reset_index(level=0, inplace=True)\n",
        "  result_pd['CryptoName'] = crypto_pd['CryptoName'].iloc[0]\n",
        "\n",
        "  #from fbprophet.diagnostics import cross_validation\n",
        "  #cv_results = cross_validation( model = model, initial = pd.to_timedelta(5,unit=\"d\"), horizon = pd.to_timedelta(5,unit=\"d\"))\n",
        "  #print(\"cv_results:\", cv_results)\n",
        "  \n",
        "  return result_pd[['ds', 'CryptoName', 'y', 'yhat', 'yhat_upper', 'yhat_lower']]\n",
        "\n",
        "\n",
        "tick= time.time()\n",
        "for cryptoName in list(df['CryptoName'].unique()):\n",
        "  pdIndividualCrypto=df[df['CryptoName'] == cryptoName][['Date','CryptoName', 'Close']].rename(columns={'Date': 'ds', 'Close': 'y'})\n",
        "  final_df=forecast_sales(pdIndividualCrypto)\n",
        "  \n",
        "\n",
        "  # calculate Mean Absolute Error (MAE) between expected and predicted values for december\n",
        "  y_true = final_df.dropna()['y'].values\n",
        "  y_pred = final_df.dropna()['yhat'].values\n",
        "\n",
        "  mae = mean_absolute_error(y_true, y_pred)\n",
        "  print(cryptoName, ': MAE: %.3f' % mae)\n",
        "\n",
        "  final_df[['y', 'yhat']].plot(title=cryptoName + ': MAE: %.3f' % mae)\n",
        "  \n",
        "tock=time.time()\n",
        "TotalTime=tock-tick\n",
        "print(\"Total time taken: {} sec.s\".format(round(tock-tick, 3)))"
      ],
      "metadata": {
        "id": "J4zUwGSdzMty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For indivisual Crypto it took:  54.514 sec.s"
      ],
      "metadata": {
        "id": "2Pg_x3cCoWZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Measuring Performance\n",
        "\n",
        "\n",
        "from Prophet.diagnostics import performance_metrics\n",
        "final_df = performance_metrics(final_df[['y', 'yhat']])\n",
        "final_df.head()"
      ],
      "metadata": {
        "id": "Sh7MfZVhWBgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df.rename(columns={'Date': 'ds'}, inplace=True)"
      ],
      "metadata": {
        "id": "dI71WR40j19p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf = spark.createDataFrame(df)\n",
        "sdf.printSchema() #data type of each col\n",
        "sdf.show(5) #It gives you head of pandas DataFrame\n",
        "sdf.count() #500 records"
      ],
      "metadata": {
        "id": "Gd7ehhD2RHmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf.select(['CryptoId']).groupby('CryptoId').agg({'CryptoId': 'count'}).show()"
      ],
      "metadata": {
        "id": "okZ7QxT7bSCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf.createOrReplaceTempView(\"Crypto\")\n",
        "spark.sql(\"select CryptoId, count(*) from Crypto group by CryptoId order by CryptoId\").show()"
      ],
      "metadata": {
        "id": "sE5k1qGPb8s1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql = \"SELECT CryptoId, Date as ds, sum(Close) as y FROM Crypto GROUP BY CryptoId, ds ORDER BY CryptoId, ds\"\n",
        "spark.sql(sql).show()"
      ],
      "metadata": {
        "id": "J9VvaACOcSQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_part = (spark.sql(sql).repartition(spark.sparkContext.defaultParallelism, ['CryptoId'])).cache()\n",
        "sdf.explain()"
      ],
      "metadata": {
        "id": "XH8c0hX2cSTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "result_schema = StructType([\n",
        "                  StructField('ds', TimestampType()),\n",
        "                  StructField('CryptoId', IntegerType()),\n",
        "                  StructField('y', DoubleType()),\n",
        "                  StructField('yhat', DoubleType()),\n",
        "                  StructField('yhat_upper', DoubleType()),\n",
        "                  StructField('yhat_lower', DoubleType())\n",
        "])"
      ],
      "metadata": {
        "id": "htWk-vY2cSZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#forecast_sales(df[['']])"
      ],
      "metadata": {
        "id": "3kMamGbrmGvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
        "@pandas_udf(result_schema, PandasUDFType.GROUPED_MAP)\n",
        "def forecast_sales(crypto_pd):\n",
        "  #model = Prophet(interval_width=0.95, seasonality_mode= 'multiplicative', weekly_seasonality=True, yearly_seasonality=True)\n",
        "  model = Prophet(interval_width=0.95, seasonality_mode= 'multiplicative', daily_seasonality=True, weekly_seasonality=True, yearly_seasonality=True)\n",
        "  model.fit(crypto_pd)\n",
        "  future_pd = model.make_future_dataframe(periods=5, freq='w')\n",
        "  forecast_pd = model.predict(future_pd)\n",
        "  f_pd = forecast_pd[['ds', 'yhat', 'yhat_upper', 'yhat_lower']].set_index('ds')\n",
        "  st_pd = crypto_pd[['ds', 'CryptoId', 'y']].set_index('ds')\n",
        "  result_pd = f_pd.join(st_pd, how='left')\n",
        "  result_pd.reset_index(level=0, inplace=True)\n",
        "  result_pd['CryptoId'] = crypto_pd['CryptoId'].iloc[0]\n",
        "\n",
        "  return result_pd[['ds', 'CryptoId', 'y', 'yhat', 'yhat_upper', 'yhat_lower']]"
      ],
      "metadata": {
        "id": "-1yMvwIqbXIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import current_date\n",
        "tick=time.time()\n",
        "results = (store_part.groupby('CryptoId').apply(forecast_sales).withColumn('training_date', current_date()))\n",
        "results.cache()\n",
        "results.show(5)\n",
        "tock=time.time()\n",
        "print(\"Total time taken: {} seconds\".format((tock-tick)/60))"
      ],
      "metadata": {
        "id": "5074IREfldRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.coalesce(1)\n",
        "print(results.count())\n",
        "results.createOrReplaceTempView('forecasted')\n",
        "spark.sql(\"SELECT CryptoId, count(*) FROM  forecasted GROUP BY CryptoId\").show()"
      ],
      "metadata": {
        "id": "ggDGoah3lx43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = results.toPandas()\n",
        "final_df.head()"
      ],
      "metadata": {
        "id": "q6YShpHaoK_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictCrypto={1: 'bitcoin', 2: 'ethereum', 3: 'cardano', 4: 'tether'}\n",
        "final_df['CryptoName']=final_df['CryptoId'].apply(lambda x: dictCrypto[x])\n",
        "final_df.head()"
      ],
      "metadata": {
        "id": "ELDaFfLfoQ19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df[final_df['CryptoName'] == 'bitcoin'][['y', 'yhat']].plot()"
      ],
      "metadata": {
        "id": "5exn6Jlbq3sS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = final_df.set_index('ds')\n",
        "for CryptoName in list(final_df.CryptoName.unique()):\n",
        "  #final_df.query('CryptoName == {}'.format(CryptoName))[['y', 'yhat']].plot()\n",
        "  \n",
        "  pdTemp=final_df[final_df['CryptoName'] == CryptoName][['y', 'yhat']]\n",
        "  \n",
        "  # calculate Mean Absolute Error (MAE) between expected and predicted values for december\n",
        "  y_true = pdTemp.dropna()['y'].values\n",
        "  y_pred = pdTemp.dropna()['yhat'].values\n",
        "\n",
        "  mae = mean_absolute_error(y_true, y_pred)\n",
        "  print(CryptoName, ': MAE: %.3f' % mae)\n",
        "\n",
        "  pdTemp[['y', 'yhat']].plot(title=CryptoName + ': MAE: %.3f' % mae)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "6v5RRpSolgCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6SyCJ6riGO8A"
      }
    }
  ]
}