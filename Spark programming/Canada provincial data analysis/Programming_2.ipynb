{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Programming 2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OOHUtexl28I"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#coding on Google Collab\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"DataFrame\").getOrCreate()\n",
        "\n",
        "# Creating spark context\n",
        "sc  = spark.sparkContext"
      ],
      "metadata": {
        "id": "y-0wNvnm4NLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Using the environmental data for each of the provinces in Canada, and weighting each piece of data by the number of cities in the province, calculate the mean temperature and mean precipitation for all of Canada for annual and each month.\n",
        "\n",
        "In each case, write a program using Python libraries of PySpark.  It would make sense to treat the data as manipulation of matrices.  Do not assume that the input data is all on the same node.\n",
        "\n",
        "Your submission should include the Spark program, and the answers (probably in a matrix of the same form as the input matrices, but without Rows for High, Low Temperatures, and columns for # of cities, and years)."
      ],
      "metadata": {
        "id": "nGviDHq7XbFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession  \n",
        "scSpark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"/content/sample_data/Python Spark SQL basic example: Reading CSV file without mentioning schema\") \\\n",
        "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "_u581vfkQavy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input file path on Google collab\n",
        "txtInput=\"/content/sample_data/Class 9 - 12  - Data for Programming - Environmental - vshort.xlsx\"\n",
        "\n",
        "import pandas as pd\n",
        "pdInput= pd.read_excel(txtInput)\n",
        "pdInput.head()"
      ],
      "metadata": {
        "id": "IHEUxdNFVMcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- I was not able to read excel file directly using pyspark hence converted pandas to pyspark df\n",
        "\n",
        "- Observation: some of the rows are nan for all the columns "
      ],
      "metadata": {
        "id": "M8PIR1FcOWNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# created spark rdd \n",
        "sparkDF = scSpark.createDataFrame(pdInput.astype(str)) # casting as string is important\n",
        "sparkDF.show()"
      ],
      "metadata": {
        "id": "hK2db68BQCxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- For each of the provinces in Canada, and weighting each piece of data by the number of cities in the province, calculate the mean temperature and mean precipitation for all of Canada for annual and each month.\n",
        "\n",
        "- In each case, write a program using Python libraries of PySpark. It would make sense to treat the data as manipulation of matrices. Do not assume that the input data is all on the same node.\n",
        "\n",
        "- Your submission should include the Spark program, and the answers (probably in a matrix of the same form as the input matrices, but without Rows for High, Low Temperatures, and columns for # of cities, and years)."
      ],
      "metadata": {
        "id": "3UkQo59RVQPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing columns # of cities and years also the rows for High, Low Temperatures\n",
        "print(sparkDF.columns)\n",
        "sparkDF=sparkDF.drop('YEARS\\xa0', '# CITIES\\xa0')\n",
        "sparkDF.show()"
      ],
      "metadata": {
        "id": "b9-pMYW3chl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting rows with values for Avg Temperature and Avg Precipitation for each province\n",
        "rddAvgTemp=sparkDF.filter(sparkDF.Alberta == \"Average Temperature (F)\") \n",
        "rddAvgPrep=sparkDF.filter(sparkDF.Alberta == \"Average Precipitation (in)\")"
      ],
      "metadata": {
        "id": "nWafELVh15IP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rddAvgTemp.show() # Average temperature for each province"
      ],
      "metadata": {
        "id": "lt4iFFFe4P21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rddAvgPrep.show() # Average precipitation for each province"
      ],
      "metadata": {
        "id": "bCdnaoyo4P9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating matrix for single province in the data\n",
        "from pyspark.mllib.linalg.distributed import RowMatrix"
      ],
      "metadata": {
        "id": "ONohWP-9Po8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop nan rows inbetween\n",
        "#sparkDF=sparkDF.na.drop('all')\n",
        "#sparkDF.show()\n",
        "\n",
        "lstColumns=rddAvgTemp.columns\n",
        "lstColumns.remove('Alberta')\n",
        "\n",
        "# Created 2 matrices for the matrix operations\n",
        "\n",
        "# Matrix 1 for Avg Temperature and Matrix 2 for Avg Precipitation\n",
        "# Creating matrix for operations\n",
        "rows=sc.parallelize(rddAvgTemp[lstColumns].rdd.map(list).collect())\n",
        "matrixAvgTemp = RowMatrix(rows)\n",
        "\n",
        "rows=sc.parallelize(rddAvgPrep[lstColumns].rdd.map(list).collect())\n",
        "matrixAvgPrecipitation = RowMatrix(rows)"
      ],
      "metadata": {
        "id": "RN6acTxex4-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performed matrix operation to calculate average or mean for all months and a year"
      ],
      "metadata": {
        "id": "wxqJDisuLO8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rddAvgPrep[lstColumns].show()\n",
        "colStats = matrixAvgPrecipitation.computeColumnSummaryStatistics()\n",
        "print(\"calculated the mean Precipitation for all of Canada for annual and each month.:\", colStats.mean())"
      ],
      "metadata": {
        "id": "z1WRI-uJK02F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rddAvgTemp[lstColumns].show()\n",
        "colStats = matrixAvgTemp.computeColumnSummaryStatistics()\n",
        "print(\"calculated the mean Temperature for all of Canada for annual and each month.:\", colStats.mean())"
      ],
      "metadata": {
        "id": "2y33hNWaK07m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}